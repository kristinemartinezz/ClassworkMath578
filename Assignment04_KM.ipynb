{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 04\n",
    "\n",
    "Due Oct 4, 11:59pm. Please submit one .ipynb file to Beachboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: right; '> Kristine Martinez </p>\n",
    "<p style='text-align: right; '> 10/21/2022 </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=6SNBUWTX3MA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class, we have covered the topic of using Robust PCA to denoise the Yale Face images, with salt and pepper noise. In particular, we have defined a function to add random salt and pepper noise. In this assignment, you are asked to defined your own function to add patch noise to the images and then try to recover the original images. That is, you will create a mask with the same shape as your data tensor which will have value one for pathces of size (20, 20) position randomly in each sample. \n",
    "\n",
    "Please refer to [Robust Tensor PCA for Yale Faces](http://jeankossaifi.com/blog/rpca.html) website, for imformation related to this assignment. You may also review my [lecture video 10](https://csulb-my.sharepoint.com/:v:/g/personal/paul_sun_csulb_edu/EfnG5I020EdEh1mCp-hx6ToBaFLO4HYgpSkf5qeQwdki4A?e=EPCWtV) as well as [jupytor notebook from lecture 10](https://nbviewer.org/github/huiprobable/MATH578F22CSULB/blob/main/Lectures/yaleB_RPCA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from matplotlib.pyplot import imread\n",
    "from scipy.ndimage.interpolation import zoom#\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fetch_cropped_yaleb(data_folder, zooming=0.5, max_n_subjects=None):\n",
    "    \"\"\"Returns a dictionary of paths\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_folder: string\n",
    "    zooming: float, optional, default is 0.5\n",
    "        factor by which to resize the images\n",
    "    max_n_subjects: {None, int}, optional, default is None\n",
    "        if not None, only the first max_n_subjects are returned\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: {\n",
    "        subjects_1: {'images': [image_1, ... image_N],\n",
    "               'ambient': image_ambient,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    images are stored as numpy arrays\n",
    "    \"\"\"\n",
    "    url = 'http://vision.ucsd.edu/extyaleb/CroppedYaleBZip/CroppedYale.zip'\n",
    "    yaleb_path = Path(data_folder).joinpath('cropped_yaleb')\n",
    "    \n",
    "    if not yaleb_path.joinpath('CroppedYale').exists():\n",
    "        yaleb_path.mkdir(parents=True)\n",
    "    \n",
    "    # If not already unzip, do it\n",
    "    if not list(yaleb_path.iterdir()):\n",
    "        zip_path = yaleb_path.joinpath('yaleb.zip')\n",
    "        \n",
    "        # If zip not already downloaded, download it\n",
    "        if not zip_path.exists():\n",
    "            urlretrieve(url, zip_path.as_posix())\n",
    "        \n",
    "        zfile = zipfile.ZipFile(zip_path.as_posix())\n",
    "        zfile.extractall(path=yaleb_path.as_posix())\n",
    "\n",
    "    yaleb = {}\n",
    "    for folder_path in yaleb_path.joinpath('CroppedYale').iterdir():\n",
    "        if max_n_subjects is not None and len(yaleb) > max_n_subjects:\n",
    "            return yaleb\n",
    "        \n",
    "        if not folder_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        video_name = folder_path.name\n",
    "        paths = sorted(list(folder_path.glob('*.pgm')))\n",
    "        images = []\n",
    "        for path in paths:\n",
    "            if 'Ambient' in path.name:\n",
    "                ambient = imread(path.as_posix())\n",
    "            else:\n",
    "                images.append(zoom(imread(path.as_posix()), zooming)[None, ...])\n",
    "                \n",
    "        data = {'images':np.concatenate(images),\n",
    "        'ambient':ambient}\n",
    "        yaleb[video_name] = data\n",
    "\n",
    "    return yaleb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '\\\\data\\\\tensorly_data\\\\cropped_yaleb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3c5590a09d52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/data/tensorly_data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_cropped_yaleb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzooming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_n_subjects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-cc1d35a7f2c6>\u001b[0m in \u001b[0;36mfetch_cropped_yaleb\u001b[1;34m(data_folder, zooming, max_n_subjects)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0myaleb_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CroppedYale'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0myaleb_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# If not already unzip, do it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '\\\\data\\\\tensorly_data\\\\cropped_yaleb'"
     ]
    }
   ],
   "source": [
    "dataset_path = '/data/tensorly_data/'\n",
    "\n",
    "data = fetch_cropped_yaleb(dataset_path, zooming=0.3, max_n_subjects=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([data[key]['images'] for key in data], axis=0)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float64)\n",
    "X -= X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualise_images(X, n_images, n_columns, randomise=True):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    indices = indices[:n_images]\n",
    "    cmap = plt.cm.Greys_r\n",
    "    n_rows = np.ceil(n_images / n_columns).astype(int)\n",
    "    fig = plt.figure(figsize=(2*n_columns, 2*58/50*n_rows))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # plot the digits: each image is 8x8 pixels\n",
    "    for i, e in enumerate(indices):\n",
    "        ax = fig.add_subplot(n_rows, n_columns, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(X[e], cmap=cmap, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_images(X, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    " \n",
    "def add_noise(X ):\n",
    "    num_images, row, col = X.shape\n",
    "    patch_noise = np.ones((20,20))\n",
    "    mask = np.zeros(X.shape) \n",
    "\n",
    "    for i in range(num_images): \n",
    "            y_coord = random.randint(0, row-21)\n",
    "            x_coord = random.randint(0, col-21)   \n",
    "            mask[i, y_coord: y_coord+20, x_coord:x_coord+20] = patch_noise\n",
    "            \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.concatenate([data[key]['images'] for key in data])\n",
    "#X = X.astype(np.float64)\n",
    "#X -= X.mean()\n",
    "mask = add_noise(X) \n",
    "mask_bool = mask.astype(bool)\n",
    "\n",
    "X[mask_bool] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_images(X, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
