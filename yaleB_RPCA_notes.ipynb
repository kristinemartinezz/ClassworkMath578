{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d4337b-955c-4f10-a15f-6142f77e5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from matplotlib.pyplot import imread\n",
    "from scipy.ndimage.interpolation import zoom#\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fetch_cropped_yaleb(data_folder, zooming=0.5, max_n_subjects=None):\n",
    "    \"\"\"Returns a dictionary of paths\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_folder: string\n",
    "    zooming: float, optional, default is 0.5\n",
    "        factor by which to resize the images\n",
    "    max_n_subjects: {None, int}, optional, default is None\n",
    "        if not None, only the first max_n_subjects are returned\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict: {\n",
    "        subjects_1: {'images': [image_1, ... image_N],\n",
    "               'ambient': image_ambient,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    images are stored as numpy arrays\n",
    "    \"\"\"\n",
    "    url = 'http://vision.ucsd.edu/extyaleb/CroppedYaleBZip/CroppedYale.zip'\n",
    "    yaleb_path = Path(data_folder).joinpath('cropped_yaleb')\n",
    "    \n",
    "    if not yaleb_path.joinpath('CroppedYale').exists():\n",
    "        yaleb_path.mkdir(parents=True)\n",
    "    \n",
    "    # If not already unzip, do it\n",
    "    if not list(yaleb_path.iterdir()):\n",
    "        zip_path = yaleb_path.joinpath('yaleb.zip')\n",
    "        \n",
    "        # If zip not already downloaded, download it\n",
    "        if not zip_path.exists():\n",
    "            urlretrieve(url, zip_path.as_posix())\n",
    "        \n",
    "        zfile = zipfile.ZipFile(zip_path.as_posix())\n",
    "        zfile.extractall(path=yaleb_path.as_posix())\n",
    "\n",
    "    yaleb = {}\n",
    "    for folder_path in yaleb_path.joinpath('CroppedYale').iterdir():\n",
    "        if max_n_subjects is not None and len(yaleb) > max_n_subjects:\n",
    "            return yaleb\n",
    "        \n",
    "        if not folder_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        video_name = folder_path.name\n",
    "        paths = sorted(list(folder_path.glob('*.pgm')))\n",
    "        images = []\n",
    "        for path in paths:\n",
    "            if 'Ambient' in path.name:\n",
    "                ambient = imread(path.as_posix())\n",
    "            else:\n",
    "                images.append(zoom(imread(path.as_posix()), zooming)[None, ...])\n",
    "                \n",
    "        data = {'images':np.concatenate(images),\n",
    "        'ambient':ambient}\n",
    "        yaleb[video_name] = data\n",
    "\n",
    "    return yaleb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98519073-37f3-4a71-89cb-7562bee014a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '\\\\data\\\\tensorly_data\\\\cropped_yaleb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/tensorly_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_cropped_yaleb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzooming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_n_subjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mfetch_cropped_yaleb\u001b[1;34m(data_folder, zooming, max_n_subjects)\u001b[0m\n\u001b[0;32m     31\u001b[0m yaleb_path \u001b[38;5;241m=\u001b[39m Path(data_folder)\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcropped_yaleb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m yaleb_path\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCroppedYale\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m---> 34\u001b[0m     \u001b[43myaleb_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# If not already unzip, do it\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(yaleb_path\u001b[38;5;241m.\u001b[39miterdir()):\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '\\\\data\\\\tensorly_data\\\\cropped_yaleb'"
     ]
    }
   ],
   "source": [
    "dataset_path = '/data/tensorly_data/'\n",
    "\n",
    "data = fetch_cropped_yaleb(dataset_path, zooming=0.3, max_n_subjects=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6594e-e82d-442f-adbb-296e7824ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e9cd3-c999-47d8-9d45-61724c512777",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12861748",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['yaleB01']['ambient'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875c0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['yaleB01']['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aaab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([data[key]['images'] for key in data], axis=0)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, data[key]['images'][0,0,0]) for key in data] #play with list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cropped_yaleb_testing(data_folder, zooming=0.5, max_n_subjects=None):\n",
    "    \n",
    "    yaleb_path = Path(data_folder).joinpath('cropped_yaleb')\n",
    "  \n",
    "    for folder_path in yaleb_path.joinpath('CroppedYale').iterdir():\n",
    "         \n",
    "        if not folder_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        video_name = folder_path.name\n",
    "        print(video_name)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15289fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_cropped_yaleb_testing(dataset_path, zooming=0.3, max_n_subjects=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float64)\n",
    "X -= X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualise_images(X, n_images, n_columns, randomise=True):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    indices = indices[:n_images]\n",
    "    cmap = plt.cm.Greys_r\n",
    "    n_rows = np.ceil(n_images / n_columns).astype(int)\n",
    "    fig = plt.figure(figsize=(2*n_columns, 2*n_rows))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # plot the digits: each image is 8x8 pixels\n",
    "    for i, e in enumerate(indices):\n",
    "        ax = fig.add_subplot(n_rows, n_columns, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(X[e], cmap=cmap, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc837bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_images(X, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    " \n",
    "def add_noise(X, percent=0.15):\n",
    "    num_images, row, col = X.shape\n",
    "    \n",
    "    n1 = int(row*col*percent)\n",
    "    for i in range(num_images):\n",
    "        \n",
    "        fmin, fmax = np.min(X[i]), np.max(X[i])\n",
    "        \n",
    "        for j in range(n1):\n",
    "    \n",
    "            y_coord=random.randint(0, row - 1)\n",
    "            x_coord=random.randint(0, col - 1)\n",
    "            scale = random.randint(0, 100)/100 #random between 0 and 1\n",
    "            val = fmin + scale*(fmax - fmin) #random betweeen fmin and fmax\n",
    "            X[i,y_coord, x_coord]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c226017",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_images(X, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0b405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
